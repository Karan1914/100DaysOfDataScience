{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the Gender column as the feature to be predicted (y)\n",
    "y = ansur_df['Gender']\n",
    "\n",
    "# Remove the Gender column to create the training data\n",
    "X = ansur_df.drop('Gender', axis=1)\n",
    "\n",
    "# Perform a 70% train and 30% test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(\"{} rows in test set vs. {} in training set. {} Features.\".format(X_test.shape[0], X_train.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SVC from sklearn.svm and accuracy_score from sklearn.metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an instance of the Support Vector Classification class\n",
    "svc = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy scores on both train and test data\n",
    "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
    "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Accuracy after dimensionality reduction\n",
    "You'll reduce the overfit with the help of dimensionality reduction. \n",
    "In this case, you'll apply a rather drastic form of dimensionality reduction by only selecting a single column \n",
    "that has some good information to distinguish between genders. \n",
    "You'll repeat the train-test split, model fit and prediction steps\n",
    "to compare the accuracy on test vs. training data.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Select just the neck circumference ('neckcircumferencebase') column from ansur_df.\n",
    "Split the data, instantiate a classifier and fit the data. This has been done for you.\n",
    "Once again calculate the accuracy scores on both training and test set.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Assign just the 'neckcircumferencebase' column from ansur_df to X\n",
    "X = ansur_df[['neckcircumferencebase']]\n",
    "\n",
    "# Split the data, instantiate a classifier and fit the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy scores on both train and test data\n",
    "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
    "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Create a VarianceThreshold feature selector\n",
    "sel = VarianceThreshold(threshold=0.001)\n",
    "\n",
    "# Fit the selector to normalized head_df\n",
    "sel.fit(head_df / head_df.mean())\n",
    "\n",
    "# Create a boolean mask\n",
    "mask = sel.get_support()\n",
    "\n",
    "# Apply the mask to create a reduced dataframe\n",
    "reduced_df = head_df.loc[:, mask]\n",
    "\n",
    "print(\"Dimensionality reduced from {} to {}.\".format(head_df.shape[1], reduced_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask on whether each feature less than 50% missing values.\n",
    "mask = school_df.isna().sum() / len(school_df) < 0.5\n",
    "\n",
    "# Create a reduced dataset by applying the mask\n",
    "reduced_df = school_df.loc[:, mask]\n",
    "\n",
    "print(school_df.shape)\n",
    "print(reduced_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
