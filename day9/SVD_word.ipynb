{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clustering Wikipedia part I\n",
    "You saw in the video that TruncatedSVD is able to perform PCA on sparse arrays in csr_matrix format, \n",
    "such as word-frequency arrays. \n",
    "Combine your knowledge of TruncatedSVD and k-means to cluster some popular pages from Wikipedia. \n",
    "In this exercise, build the pipeline. In the next exercise,\n",
    "you'll apply it to the word-frequency array of some Wikipedia articles.\n",
    "\n",
    "Create a Pipeline object consisting of a TruncatedSVD followed by KMeans. \n",
    "(This time, we've precomputed the word-frequency matrix for you, so there's no need for a TfidfVectorizer).\"\"\"\n",
    "\n",
    "\"\"\"Import:\n",
    "TruncatedSVD from sklearn.decomposition.\n",
    "KMeans from sklearn.cluster.\n",
    "make_pipeline from sklearn.pipeline.\n",
    "Create a TruncatedSVD instance called svd with n_components=50.\n",
    "Create a KMeans instance called kmeans with n_clusters=6.\n",
    "Create a pipeline called pipeline consisting of svd and kmeans.\"\"\"\n",
    "\n",
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd,kmeans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clustering Wikipedia part II\n",
    "It is now time to put your pipeline from the previous exercise to work!\n",
    "You are given an array articles of tf-idf word-frequencies of some popular Wikipedia articles, \n",
    "and a list titles of their titles. Use your pipeline to cluster the Wikipedia articles.\n",
    "\n",
    "A solution to the previous exercise has been pre-loaded for you, \n",
    "so a Pipeline pipeline chaining TruncatedSVD with KMeans is available.\"\"\"\n",
    "\n",
    "\"\"\"Import pandas as pd.\n",
    "Fit the pipeline to the word-frequency array articles.\n",
    "Predict the cluster labels.\n",
    "Align the cluster labels with the list titles of article titles by creating a DataFrame df with labels and titles as columns. This has been done for you.\n",
    "Use the .sort_values() method of df to sort the DataFrame by the 'label' column, and print the result.\n",
    "Hit 'Submit Answer' and take a moment to investigate your amazing clustering of Wikipedia pages!\"\"\"\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Fit the pipeline to articles\n",
    "pipeline.fit(articles)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(articles)\n",
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values('label'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
