{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Zero Matrix factorization\n",
    "\"\"\"\n",
    "NMF applied to Wikipedia articles\n",
    "In the video, you saw NMF applied to transform a toy word-frequency array.\n",
    "Now it's your turn to apply NMF, this time using the tf-idf word-frequency array of Wikipedia articles,\n",
    "given as a csr matrix articles. \n",
    "Here, fit the model and transform the articles.\n",
    "In the next exercise, you'll explore the result.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Import NMF from sklearn.decomposition.\n",
    "Create an NMF instance called model with 6 components.\n",
    "Fit the model to the word count data articles.\n",
    "Use the .transform() method of model to transform articles, and assign the result to nmf_features.\n",
    "Print nmf_features to get a first idea what it looks like.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NMF features of the Wikipedia articles\n",
    "Now you will explore the NMF features you created in the previous exercise. \n",
    "A solution to the previous exercise has been pre-loaded, so the array nmf_features is available. \n",
    "Also available is a list titles giving the title of each Wikipedia article.\n",
    "\n",
    "When investigating the features, notice that for both actors, \n",
    "the NMF feature 3 has by far the highest value. \n",
    "This means that both articles are reconstructed using mainly the 3rd NMF component. \n",
    "In the next video, you'll see why: NMF components represent topics (for instance, acting!).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Import pandas as pd.\n",
    "Create a DataFrame df from nmf_features using pd.DataFrame(). \n",
    "Set the index to titles using index=titles.\n",
    "Use the .loc[] accessor of df to select the row with title 'Anne Hathaway', and print the result. \n",
    "These are the NMF features for the article about the actress Anne Hathaway.\n",
    "Repeat the last step for 'Denzel Washington' (another actor).\n",
    "\"\"\"\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a pandas DataFrame: df\n",
    "df = pd.DataFrame(nmf_features,index=titles)\n",
    "\n",
    "# Print the row for 'Anne Hathaway'\n",
    "print(df.loc['Anne Hathaway'])\n",
    "\n",
    "# Print the row for 'Denzel Washington'\n",
    "print(df.loc['Denzel Washington'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NMF learns topics of documents\n",
    "In the video, you learned when NMF is applied to documents, \n",
    "the components correspond to topics of documents, \n",
    "and the NMF features reconstruct the documents from the topics.\n",
    "Verify this for yourself for the NMF model that you built earlier using the Wikipedia articles. \n",
    "Previously, you saw that the 3rd NMF feature value was high for the articles about actors Anne Hathaway and Denzel Washington. \n",
    "In this exercise, identify the topic of the corresponding NMF component.\n",
    "\n",
    "The NMF model you built earlier is available as model, \n",
    "while words is a list of the words that label the columns of the word-frequency array.\n",
    "\n",
    "After you are done, take a moment to recognise the topic that the articles about Anne Hathaway and Denzel Washington have in common!\"\"\"\n",
    "\n",
    "\"\"\"Import pandas as pd.\n",
    "Create a DataFrame components_df from model.components_,\n",
    "setting columns=words so that columns are labeled by the words.\n",
    "Print components_df.shape to check the dimensions of the DataFrame.\n",
    "Use the .iloc[] accessor on the DataFrame components_df to select row 3. \n",
    "Assign the result to component.\n",
    "Call the .nlargest() method of component, and print the result.\n",
    "This gives the five words with the highest values for that component.\"\"\"\n",
    "\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "components_df = pd.DataFrame(model.components_,columns=words)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3,:]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
